{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-29T22:35:17.983581Z",
     "start_time": "2025-10-29T22:35:13.278169Z"
    }
   },
   "source": [
    "import logging\n",
    "from logging import getLogger\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow.dataset as ds\n",
    "import torch\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "from recbole.data.interaction import Interaction\n",
    "from recbole.model.sequential_recommender import GRU4Rec\n",
    "from recbole.trainer import Trainer\n",
    "from recbole.utils import init_seed, init_logger\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 19:35:15.960636: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-10-29 19:35:15.960695: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-10-29 19:35:15.991149: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-10-29 19:35:16.056714: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-29 19:35:17.087658: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T22:35:18.589948Z",
     "start_time": "2025-10-29T22:35:18.108462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MAX_ITEM = 30\n",
    "\n",
    "parameter_dict = {\n",
    "    'model': 'GRU4Rec',\n",
    "    'dataset': 'eventos_vix',\n",
    "    'data_path': 'dataset/',\n",
    "    'show_progress': True,\n",
    "\n",
    "    'USER_ID_FIELD': 'session_id',\n",
    "    'ITEM_ID_FIELD': 'item_id',\n",
    "    'TIME_FIELD': 'timestamp',\n",
    "    'load_col': {\n",
    "        'inter': ['session_id', 'item_id', 'timestamp']\n",
    "    },\n",
    "    'train_neg_sample_args': None,                # no negative sampling (use full item ranking)\n",
    "    'epochs': 40,                                 # number of training epochs\n",
    "    'stopping_step': 10,                           # stop early if no improvement after 3 valid steps\n",
    "\n",
    "    'eval_batch_size': 1024,                      # batch size during evaluation\n",
    "    'train_batch_size': 1024,                     # (optional) batch size for training\n",
    "    'enable_amp': True,                           # (optional) enable mixed-precision training\n",
    "    'MAX_ITEM_LIST_LENGTH': MAX_ITEM,             # max number of past items used in sequence\n",
    "    'eval_args': {\n",
    "        'split': {'RS': [8, 1, 1]},               # random split: 90% train, 10% valid, 0% test\n",
    "        'group_by': 'user',                       # group data per user/session\n",
    "        'order': 'TO',                            # respect temporal order\n",
    "        'mode': 'full'                            # use full item list for evaluation\n",
    "    }\n",
    "}\n",
    "\n",
    "config = Config(config_dict=parameter_dict)\n",
    "init_seed(config['seed'], config['reproducibility'])\n",
    "\n",
    "init_logger(config)\n",
    "logger = getLogger()\n",
    "\n",
    "c_handler = logging.StreamHandler()\n",
    "c_handler.setLevel(logging.INFO)\n",
    "logger.addHandler(c_handler)\n",
    "\n",
    "logger.info(config)"
   ],
   "id": "ee166ea6feb2736d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29 Oct 19:35    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = dataset/eventos_vix\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 40\n",
      "train_batch_size = 1024\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [8, 1, 1]}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = True\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 1024\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = session_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['session_id', 'item_id', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 30\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = True\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "hidden_size = 128\n",
      "num_layers = 1\n",
      "dropout_prob = 0.3\n",
      "loss_type = CE\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.SEQUENTIAL\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cuda\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "\n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = dataset/eventos_vix\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 40\n",
      "train_batch_size = 1024\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [8, 1, 1]}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = True\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 1024\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = session_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['session_id', 'item_id', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 30\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = True\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "hidden_size = 128\n",
      "num_layers = 1\n",
      "dropout_prob = 0.3\n",
      "loss_type = CE\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.SEQUENTIAL\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cuda\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T22:36:14.546935Z",
     "start_time": "2025-10-29T22:35:18.636517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = create_dataset(config)\n",
    "logger.info(dataset)"
   ],
   "id": "806ff9ac060189d8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hygo2025/Development/projects/kepler/.venv/lib/python3.9/site-packages/recbole/data/dataset/dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "/home/hygo2025/Development/projects/kepler/.venv/lib/python3.9/site-packages/recbole/data/dataset/dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
      "29 Oct 19:36    INFO  eventos_vix\n",
      "The number of users: 218201\n",
      "Average actions of users: 66.54326306141155\n",
      "The number of items: 67542\n",
      "Average actions of items: 214.97668083090272\n",
      "The number of inters: 14519740\n",
      "The sparsity of the dataset: 99.9014791417218%\n",
      "Remain Fields: ['session_id', 'item_id', 'timestamp']\n",
      "eventos_vix\n",
      "The number of users: 218201\n",
      "Average actions of users: 66.54326306141155\n",
      "The number of items: 67542\n",
      "Average actions of items: 214.97668083090272\n",
      "The number of inters: 14519740\n",
      "The sparsity of the dataset: 99.9014791417218%\n",
      "Remain Fields: ['session_id', 'item_id', 'timestamp']\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training",
   "id": "128dfbe43f91ffb7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T22:40:24.053617Z",
     "start_time": "2025-10-29T22:36:14.551740Z"
    }
   },
   "cell_type": "code",
   "source": "train_data, valid_data, test_data = data_preparation(config, dataset)",
   "id": "435408f5a78efb86",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29 Oct 19:40    INFO  [Training]: train_batch_size = [1024] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\n",
      "[Training]: train_batch_size = [1024] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\n",
      "29 Oct 19:40    INFO  [Evaluation]: eval_batch_size = [1024] eval_args: [{'split': {'RS': [8, 1, 1]}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "[Evaluation]: eval_batch_size = [1024] eval_args: [{'split': {'RS': [8, 1, 1]}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-10-29T22:40:32.124373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = GRU4Rec(config, train_data.dataset).to(config['device'])\n",
    "logger.info(model)\n",
    "\n",
    "trainer = Trainer(config, model)\n",
    "\n",
    "best_valid_score, best_valid_result = trainer.fit(train_data, valid_data)"
   ],
   "id": "a1d9a28f00534b41",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29 Oct 19:40    INFO  GRU4Rec(\n",
      "  (item_embedding): Embedding(67542, 64, padding_idx=0)\n",
      "  (emb_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (gru_layers): GRU(64, 128, bias=False, batch_first=True)\n",
      "  (dense): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (loss_fct): CrossEntropyLoss()\n",
      ")\n",
      "Trainable parameters: 4404672\n",
      "GRU4Rec(\n",
      "  (item_embedding): Embedding(67542, 64, padding_idx=0)\n",
      "  (emb_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (gru_layers): GRU(64, 128, bias=False, batch_first=True)\n",
      "  (dense): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (loss_fct): CrossEntropyLoss()\n",
      ")\n",
      "Trainable parameters: 4404672\n",
      "/home/hygo2025/Development/projects/kepler/.venv/lib/python3.9/site-packages/recbole/trainer/trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T17:46:59.122492Z",
     "start_time": "2025-10-22T17:46:59.115292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def recommend_for_session(external_session_id, model, dataset, top_k=10):\n",
    "    session_field = dataset.uid_field\n",
    "    item_field = dataset.iid_field\n",
    "    time_field = dataset.time_field\n",
    "\n",
    "    internal_session_id = dataset.token2id(session_field, external_session_id)\n",
    "\n",
    "    inter_feat = dataset.inter_feat\n",
    "\n",
    "    inter_df = pd.DataFrame({\n",
    "        session_field: inter_feat[session_field].tolist(),\n",
    "        item_field: inter_feat[item_field].tolist(),\n",
    "        time_field: inter_feat[time_field].tolist(),\n",
    "    })\n",
    "\n",
    "    session_history = (\n",
    "        inter_df\n",
    "        .loc[inter_df[session_field] == internal_session_id]\n",
    "        .sort_values(by=time_field)\n",
    "    )\n",
    "\n",
    "    internal_item_ids = session_history[item_field].tolist()\n",
    "\n",
    "    item_list_field = item_field + '_list'\n",
    "\n",
    "    interaction = Interaction({\n",
    "        session_field: torch.tensor([internal_session_id]),\n",
    "        item_list_field: torch.tensor([internal_item_ids]),\n",
    "        'item_length': torch.tensor([len(internal_item_ids)]),\n",
    "    })\n",
    "\n",
    "    interaction = interaction.to(model.device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        scores = model.full_sort_predict(interaction)\n",
    "\n",
    "    scores = scores.view(-1)\n",
    "    top_k_scores, top_k_indices = torch.topk(scores, k=top_k)\n",
    "\n",
    "    external_item_ids = dataset.id2token(item_field, top_k_indices.cpu().numpy())\n",
    "\n",
    "    print(f\"Top {top_k} itens recomendados para a sessão '{external_session_id}':\\n\")\n",
    "    for i, item_id in enumerate(external_item_ids):\n",
    "        score = top_k_scores[i].item()\n",
    "        print(f\"  {i+1}. Item ID: {item_id} (Score: {score:.4f})\")\n",
    "\n",
    "    print(\",\".join([str(item_id) for item_id in external_item_ids]))\n",
    "\n",
    "    return external_item_ids, top_k_scores.cpu().numpy()"
   ],
   "id": "7c65bf2ad8cf0fa4",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T14:37:11.050192Z",
     "start_time": "2025-10-22T14:37:11.038882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def recommend_for_sessions(external_session_id, model, dataset, top_k=10):\n",
    "    session_field = dataset.uid_field\n",
    "    item_field = dataset.iid_field\n",
    "    time_field = dataset.time_field\n",
    "\n",
    "    internal_session_id = dataset.token2id(session_field, external_session_id)\n",
    "    inter_feat = dataset.inter_feat\n",
    "\n",
    "    inter_df = pd.DataFrame({\n",
    "        session_field: inter_feat[session_field].tolist(),\n",
    "        item_field: inter_feat[item_field].tolist(),\n",
    "        time_field: inter_feat[time_field].tolist(),\n",
    "    })\n",
    "\n",
    "    session_history = (\n",
    "        inter_df[inter_df[session_field] == internal_session_id]\n",
    "        .sort_values(by=time_field)\n",
    "    )\n",
    "    internal_item_ids = session_history[item_field].tolist()\n",
    "\n",
    "    item_list_field = dataset.iid_field + '_list'\n",
    "    user_field = dataset.uid_field\n",
    "\n",
    "    interaction = Interaction({\n",
    "        user_field: torch.tensor([internal_session_id]),\n",
    "        item_list_field: torch.tensor([internal_item_ids]),\n",
    "        'item_length': torch.tensor([len(internal_item_ids)]),\n",
    "    })\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      scores = model.full_sort_predict(interaction.to(model.device))\n",
    "\n",
    "    top_k_indices = torch.topk(scores[0], k=top_k).indices.tolist()\n",
    "    external_item_ids = dataset.id2token(dataset.iid_field, top_k_indices)\n",
    "\n",
    "    print(f\"Top {top_k} itens recomendados para a sessão {external_session_id}:\")\n",
    "    for internal_id, external_id in zip(top_k_indices, external_item_ids):\n",
    "        print(f\"  Internal ID: {internal_id}  →  External ID: {external_id}\")\n",
    "\n",
    "    return external_item_ids"
   ],
   "id": "50dbc5b583282a88",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T17:47:05.088933Z",
     "start_time": "2025-10-22T17:47:02.279140Z"
    }
   },
   "cell_type": "code",
   "source": "recommend_for_session('999', model, dataset, top_k=10)",
   "id": "acaadd1533caf078",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 itens recomendados para a sessão '999':\n",
      "\n",
      "  1. Item ID: 54358 (Score: 28.9674)\n",
      "  2. Item ID: 48208 (Score: 27.3849)\n",
      "  3. Item ID: 6318 (Score: 26.3049)\n",
      "  4. Item ID: 27709 (Score: 26.1470)\n",
      "  5. Item ID: 54058 (Score: 26.1249)\n",
      "  6. Item ID: 22540 (Score: 25.7301)\n",
      "  7. Item ID: 10039 (Score: 25.3491)\n",
      "  8. Item ID: 26566 (Score: 25.3441)\n",
      "  9. Item ID: 29556 (Score: 25.3304)\n",
      "  10. Item ID: 34513 (Score: 25.2866)\n",
      "54358,48208,6318,27709,54058,22540,10039,26566,29556,34513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array(['54358', '48208', '6318', '27709', '54058', '22540', '10039',\n",
       "        '26566', '29556', '34513'], dtype='<U5'),\n",
       " array([28.967402, 27.384941, 26.304882, 26.146965, 26.124907, 25.73013 ,\n",
       "        25.349087, 25.34414 , 25.330423, 25.28663 ], dtype=float32))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "base_path = \"/home/hygo2025/Documents/data/processed_data/listings\"\n",
    "\n",
    "dataset = ds.dataset(base_path, format=\"parquet\", partitioning=\"hive\")\n",
    "table = dataset.to_table()\n",
    "\n",
    "df = table.to_pandas()\n",
    "\n",
    "print(df.shape)\n",
    "print(df.columns.tolist())\n",
    "df.head()\n",
    "\n",
    "\n"
   ],
   "id": "89c70a95162ae28b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "38c4620aaefe26f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T14:39:25.403437Z",
     "start_time": "2025-10-22T14:39:25.398556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "session_field = dataset.uid_field\n",
    "try:\n",
    "    first_internal_id = dataset.inter_feat[session_field][0].item()\n",
    "    external_id_list = dataset.id2token(session_field, [first_internal_id])\n",
    "    if external_id_list:\n",
    "        external_id_to_print = external_id_list[0]\n",
    "        print(f\"First external session ID: {external_id_to_print}\")\n",
    "    else:\n",
    "        print(\"No external session ID found for the first internal ID.\")\n",
    "except KeyError:\n",
    "    print(f\"Session field '{session_field}' not found in dataset.inter_feat.\")\n",
    "except IndexError:\n",
    "    print(\"No data found in dataset.inter_feat.\")"
   ],
   "id": "340ee14f2f40f5c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First external session ID: 999\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "saved_model_path = \"saved/Gru\"\n",
    "checkpoint = torch.load(saved_model_path, weights_only=False)\n",
    "\n",
    "config = checkpoint[\"config\"]\n",
    "init_seed(config['seed'], config['reproducibility'])\n",
    "init_logger(config)\n",
    "dataset = create_dataset(config)\n",
    "\n",
    "model = GRU4Rec(config, dataset).to(config['device'])\n",
    "\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "model.eval()"
   ],
   "id": "c8aad99df56856b3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
