{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-25T16:48:30.938865Z",
     "start_time": "2025-09-25T16:48:27.178490Z"
    }
   },
   "source": [
    "import random\n",
    "import warnings\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-25 13:48:28.038779: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-09-25 13:48:28.038843: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-09-25 13:48:28.040265: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-09-25 13:48:28.049420: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-25 13:48:29.771030: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T16:48:31.198539Z",
     "start_time": "2025-09-25T16:48:31.173654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def load_ml_1m():\n",
    "    # download and extract zip file\n",
    "    tf.keras.utils.get_file(\n",
    "        \"ml-1m.zip\",\n",
    "        \"http://files.grouplens.org/datasets/movielens/ml-1m.zip\",\n",
    "        cache_dir=\".\",\n",
    "        cache_subdir=\".\",\n",
    "        extract=True,\n",
    "    )\n",
    "    # read and merge data into same table\n",
    "    cur_path = Path(\".\").absolute()\n",
    "    ratings = pd.read_csv(\n",
    "        cur_path / \"ml-1m\" / \"ratings.dat\",\n",
    "        sep=\"::\",\n",
    "        usecols=[0, 1, 2, 3],\n",
    "        names=[\"user\", \"item\", \"rating\", \"time\"],\n",
    "    )\n",
    "    users = pd.read_csv(\n",
    "        cur_path / \"ml-1m\" / \"users.dat\",\n",
    "        sep=\"::\",\n",
    "        usecols=[0, 1, 2, 3],\n",
    "        names=[\"user\", \"sex\", \"age\", \"occupation\"],\n",
    "    )\n",
    "    items = pd.read_csv(\n",
    "        cur_path / \"ml-1m\" / \"movies.dat\",\n",
    "        sep=\"::\",\n",
    "        usecols=[0, 2],\n",
    "        names=[\"item\", \"genre\"],\n",
    "        encoding=\"iso-8859-1\",\n",
    "    )\n",
    "    items[[\"genre1\", \"genre2\", \"genre3\"]] = (\n",
    "        items[\"genre\"].str.split(r\"|\", expand=True).fillna(\"missing\").iloc[:, :3]\n",
    "    )\n",
    "    items.drop(\"genre\", axis=1, inplace=True)\n",
    "    data = ratings.merge(users, on=\"user\").merge(items, on=\"item\")\n",
    "    data.rename(columns={\"rating\": \"label\"}, inplace=True)\n",
    "    # random shuffle data\n",
    "    data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    return data"
   ],
   "id": "ea98b900bc4f6bdc",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T16:48:41.744557Z",
     "start_time": "2025-09-25T16:48:31.267684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = load_ml_1m()\n",
    "print(\"data shape:\", data.shape)"
   ],
   "id": "9e302345963285e2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
      "5917549/5917549 [==============================] - 1s 0us/step\n",
      "data shape: (1000209, 10)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T16:48:42.013849Z",
     "start_time": "2025-09-25T16:48:41.992884Z"
    }
   },
   "cell_type": "code",
   "source": "data.iloc[random.choices(range(len(data)), k=10)]  # randomly select 10 rows",
   "id": "2bb711ada5b9d28a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        user  item  label       time sex  age  occupation     genre1  \\\n",
       "570749  1125  1911      2  975625119   F   18           4     Comedy   \n",
       "375697  3756  1801      4  966101466   M   18          12     Action   \n",
       "279993  3103  3801      5  969566597   M   25          20      Drama   \n",
       "618961  5137  1265      5  964337733   M   18          18     Comedy   \n",
       "51686   4456  1566      4  965230295   F   35           2  Adventure   \n",
       "463716  4141   628      5  965349185   M   35          17      Drama   \n",
       "503364  2608  1957      5  973728054   F   25           1      Drama   \n",
       "99385   2419  3506      3  974248046   M   25           0     Comedy   \n",
       "363722  5026  3113      3  962586716   M   25          17     Action   \n",
       "144824  1387  3685      2  974768055   F   50          13     Comedy   \n",
       "\n",
       "           genre2      genre3  \n",
       "570749    missing     missing  \n",
       "375697      Drama     Romance  \n",
       "279993    Mystery     missing  \n",
       "618961    Romance     missing  \n",
       "51686   Animation  Children's  \n",
       "463716   Thriller     missing  \n",
       "503364    missing     missing  \n",
       "99385       Drama     missing  \n",
       "363722   Thriller     missing  \n",
       "144824      Drama     Romance  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>label</th>\n",
       "      <th>time</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>genre1</th>\n",
       "      <th>genre2</th>\n",
       "      <th>genre3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>570749</th>\n",
       "      <td>1125</td>\n",
       "      <td>1911</td>\n",
       "      <td>2</td>\n",
       "      <td>975625119</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375697</th>\n",
       "      <td>3756</td>\n",
       "      <td>1801</td>\n",
       "      <td>4</td>\n",
       "      <td>966101466</td>\n",
       "      <td>M</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>Action</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279993</th>\n",
       "      <td>3103</td>\n",
       "      <td>3801</td>\n",
       "      <td>5</td>\n",
       "      <td>969566597</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Mystery</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618961</th>\n",
       "      <td>5137</td>\n",
       "      <td>1265</td>\n",
       "      <td>5</td>\n",
       "      <td>964337733</td>\n",
       "      <td>M</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Romance</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51686</th>\n",
       "      <td>4456</td>\n",
       "      <td>1566</td>\n",
       "      <td>4</td>\n",
       "      <td>965230295</td>\n",
       "      <td>F</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>Animation</td>\n",
       "      <td>Children's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463716</th>\n",
       "      <td>4141</td>\n",
       "      <td>628</td>\n",
       "      <td>5</td>\n",
       "      <td>965349185</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>17</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503364</th>\n",
       "      <td>2608</td>\n",
       "      <td>1957</td>\n",
       "      <td>5</td>\n",
       "      <td>973728054</td>\n",
       "      <td>F</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>Drama</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99385</th>\n",
       "      <td>2419</td>\n",
       "      <td>3506</td>\n",
       "      <td>3</td>\n",
       "      <td>974248046</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Drama</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363722</th>\n",
       "      <td>5026</td>\n",
       "      <td>3113</td>\n",
       "      <td>3</td>\n",
       "      <td>962586716</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>Action</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144824</th>\n",
       "      <td>1387</td>\n",
       "      <td>3685</td>\n",
       "      <td>2</td>\n",
       "      <td>974768055</td>\n",
       "      <td>F</td>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T16:48:42.779808Z",
     "start_time": "2025-09-25T16:48:42.270689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from libreco.data import random_split\n",
    "\n",
    "# split data into three folds for training, evaluating and testing\n",
    "first_half_data = data[: (len(data) // 2)]\n",
    "train_data, eval_data, test_data = random_split(first_half_data, multi_ratios=[0.8, 0.1, 0.1], seed=42)"
   ],
   "id": "3cbaa786a04d7dbf",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T16:48:42.883788Z",
     "start_time": "2025-09-25T16:48:42.880505Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"first half data shape:\", first_half_data.shape)",
   "id": "a6c7d9371b419ba9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first half data shape: (500104, 10)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T16:48:43.953455Z",
     "start_time": "2025-09-25T16:48:43.068243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from libreco.data import DatasetFeat\n",
    "\n",
    "sparse_col = [\"sex\", \"occupation\", \"genre1\", \"genre2\", \"genre3\"]\n",
    "dense_col = [\"age\"]\n",
    "user_col = [\"sex\", \"age\", \"occupation\"]\n",
    "item_col = [\"genre1\", \"genre2\", \"genre3\"]\n",
    "\n",
    "train_data, data_info = DatasetFeat.build_trainset(train_data, user_col, item_col, sparse_col, dense_col)\n",
    "eval_data = DatasetFeat.build_evalset(eval_data)\n",
    "test_data = DatasetFeat.build_testset(test_data)"
   ],
   "id": "a6f86922c4443847",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T16:48:43.960346Z",
     "start_time": "2025-09-25T16:48:43.957551Z"
    }
   },
   "cell_type": "code",
   "source": "print(data_info)",
   "id": "d720a296215ef427",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_users: 6040, n_items: 3580, data density: 1.8502 %\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T16:48:45.726977Z",
     "start_time": "2025-09-25T16:48:44.154879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from libreco.algorithms import WideDeep"
   ],
   "id": "4095bf3004824e23",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hygo2025/Development/projects/kepler/.venv/lib/python3.9/site-packages/tensorflow/python/compat/v2_compat.py:108: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T16:49:02.301404Z",
     "start_time": "2025-09-25T16:48:45.731835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = WideDeep(\n",
    "    task=\"ranking\",\n",
    "    data_info=data_info,\n",
    "    embed_size=16,\n",
    "    n_epochs=2,\n",
    "    loss_type=\"cross_entropy\",\n",
    "    lr={\"wide\": 0.05, \"deep\": 7e-4},\n",
    "    batch_size=2048,\n",
    "    use_bn=True,\n",
    "    hidden_units=(128, 64, 32),\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_data,\n",
    "    neg_sampling=True,  # perform negative sampling on training and eval data\n",
    "    verbose=2,\n",
    "    shuffle=True,\n",
    "    eval_data=eval_data,\n",
    "    metrics=[\"loss\", \"roc_auc\", \"precision\", \"recall\", \"ndcg\"],\n",
    ")"
   ],
   "id": "80d00c801d179770",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start time: \u001B[35m2025-09-25 13:48:45\u001B[0m\n",
      "WARNING:tensorflow:From /home/hygo2025/Development/projects/kepler/.venv/lib/python3.9/site-packages/keras/src/layers/normalization/batch_normalization.py:883: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-25 13:48:45.901786: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-25 13:48:45.903364: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-25 13:48:45.903495: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-25 13:48:45.968228: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-25 13:48:45.968439: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-25 13:48:45.968571: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-25 13:48:45.968660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21875 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-09-25 13:48:46,092 - WARNING - From /home/hygo2025/Development/projects/kepler/.venv/lib/python3.9/site-packages/keras/src/layers/normalization/batch_normalization.py:883: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total params: \u001B[33m192,481\u001B[0m | embedding params: \u001B[33m165,177\u001B[0m | network params: \u001B[33m27,304\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-25 13:48:46.737169: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "train:   0%|          | 0/391 [00:00<?, ?it/s]2025-09-25 13:48:47.377102: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:225] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.9\n",
      "2025-09-25 13:48:47.377122: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:228] Used ptxas at ptxas\n",
      "2025-09-25 13:48:47.377170: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-09-25 13:48:47.543457: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-09-25 13:48:47.543485: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-09-25 13:48:47.543500: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-09-25 13:48:47.545515: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-09-25 13:48:47.545532: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-09-25 13:48:47.545833: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-09-25 13:48:47.547819: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-09-25 13:48:47.548728: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-09-25 13:48:47.735373: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-09-25 13:48:47.792317: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-09-25 13:48:47.835954: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-09-25 13:48:47.865170: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-09-25 13:48:47.935473: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-09-25 13:48:47.991164: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-09-25 13:48:48.057103: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2025-09-25 13:48:48.057128: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "train: 100%|██████████| 391/391 [00:02<00:00, 144.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 elapsed: 2.704s\n",
      "\t \u001B[32mtrain_loss: 0.9671\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_pointwise: 100%|██████████| 13/13 [00:00<00:00, 169.42it/s]\n",
      "eval_listwise: 100%|██████████| 2817/2817 [00:05<00:00, 553.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t eval log_loss: 0.5922\n",
      "\t eval roc_auc: 0.7903\n",
      "\t eval precision@10: 0.0246\n",
      "\t eval recall@10: 0.0372\n",
      "\t eval ndcg@10: 0.0983\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 391/391 [00:01<00:00, 248.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 elapsed: 1.574s\n",
      "\t \u001B[32mtrain_loss: 0.4991\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_pointwise: 100%|██████████| 13/13 [00:00<00:00, 429.85it/s]\n",
      "eval_listwise: 100%|██████████| 2817/2817 [00:05<00:00, 553.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t eval log_loss: 0.4917\n",
      "\t eval roc_auc: 0.8365\n",
      "\t eval precision@10: 0.0322\n",
      "\t eval recall@10: 0.0525\n",
      "\t eval ndcg@10: 0.1341\n",
      "==============================\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T16:49:07.831510Z",
     "start_time": "2025-09-25T16:49:02.397210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from libreco.evaluation import evaluate\n",
    "\n",
    "evaluate(\n",
    "    model=model,\n",
    "    data=test_data,\n",
    "    neg_sampling=True,  # perform negative sampling on test data\n",
    "    metrics=[\"loss\", \"roc_auc\", \"precision\", \"recall\", \"ndcg\"],\n",
    ")"
   ],
   "id": "ce29e989a7681e52",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval_pointwise: 100%|██████████| 13/13 [00:00<00:00, 347.88it/s]\n",
      "eval_listwise: 100%|██████████| 2798/2798 [00:05<00:00, 556.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.49328231155373836,\n",
       " 'roc_auc': 0.8353801910786779,\n",
       " 'precision': 0.030879199428162977,\n",
       " 'recall': 0.04892803975512679,\n",
       " 'ndcg': 0.12823252881266994}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T16:49:07.934230Z",
     "start_time": "2025-09-25T16:49:07.926117Z"
    }
   },
   "cell_type": "code",
   "source": "model.recommend_user(user=1, n_rec=3)",
   "id": "ad4f169d3c30b588",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: array([3751, 1097, 2355])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T16:49:08.061827Z",
     "start_time": "2025-09-25T16:49:08.054584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "model.recommend_user(user=[1, 2, 3], n_rec=3)"
   ],
   "id": "98a56a9f5738c58",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: array([3751, 1097, 2355]),\n",
       " 2: array([1198, 2858, 2028]),\n",
       " 3: array([1580, 1197, 2028])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T16:49:08.223211Z",
     "start_time": "2025-09-25T16:49:08.215357Z"
    }
   },
   "cell_type": "code",
   "source": "model.recommend_user(user=1, n_rec=3, user_feats={\"sex\": \"M\", \"age\": 33})",
   "id": "394f9801e6a9aa40",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: array([2858, 1197,  110])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T16:49:08.384068Z",
     "start_time": "2025-09-25T16:49:08.376425Z"
    }
   },
   "cell_type": "code",
   "source": "model.recommend_user(user=1, n_rec=3, user_feats={\"occupation\": 17})",
   "id": "72c3061f63d008ea",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: array([3751, 2858, 2355])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
